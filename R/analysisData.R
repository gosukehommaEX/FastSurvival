#' Create analysis datasets from clinical trial simulation data
#'
#' This function creates analysis datasets from simulation data generated by simTrial()
#' based on either target number of events or follow-up times for interim and final
#' analyses using data.table for maximum performance. It handles data cutoffs and
#' censoring appropriately for time-to-event analysis.
#'
#' @param data A data.table containing simulation data generated by \code{\link{simTrial}}.
#'   Must contain columns: simID, group, accrual.time, surv.time, dropout.time,
#'   tte, total, dropout. May optionally contain subgroup column.
#' @param E A numeric vector specifying the target number of events for each analysis.
#'   Each element represents a different analysis timepoint (e.g., interim, final).
#'   Cannot be used with followup. Default is NULL.
#' @param followup A numeric vector specifying the follow-up times for each analysis.
#'   Each element represents the calendar time from study start for analysis.
#'   Cannot be used with E. Default is NULL.
#'
#' @return A data.table containing the analysis datasets with the following columns:
#' \describe{
#'   \item{analysis}{Analysis number (1, 2, 3, ...) corresponding to each element in E or followup}
#'   \item{simID}{Simulation iteration ID (1 to nsim)}
#'   \item{group}{Group indicator (1, 2, 3, ...)}
#'   \item{subgroup}{Subgroup indicator (A, B, C, ...) - only present if subgroups are specified}
#'   \item{accrual.time}{Patient accrual time from study start}
#'   \item{surv.time}{Original survival time from patient entry}
#'   \item{dropout.time}{Original dropout time from patient entry}
#'   \item{tte}{Time-to-event (adjusted for analysis cutoff)}
#'   \item{total}{Original total time from study start}
#'   \item{dropout}{Original dropout indicator from simTrial}
#'   \item{analysis.time}{Analysis cutoff time (calendar time from study start)}
#'   \item{event}{Event indicator for analysis (1 = event occurred by cutoff, 0 = censored at cutoff)}
#' }
#'
#' @details
#' This function is essential for simulating adaptive trial designs and interim analyses.
#' It supports two main approaches:
#'
#' \describe{
#'   \item{Event-driven Analysis (E parameter)}{
#'     Analysis is triggered when a target number of events is observed across all
#'     groups. The analysis time is determined as the calendar time when the E-th
#'     event occurs. This is common in oncology trials where analyses are performed
#'     after accumulating a predetermined number of deaths.
#'   }
#'   \item{Time-driven Analysis (followup parameter)}{
#'     Analysis is performed at predetermined calendar times from study start,
#'     regardless of the number of events observed. This is common in cardiovascular
#'     trials with planned interim analyses at fixed timepoints.
#'   }
#' }
#'
#' For each analysis, the function:
#' \itemize{
#'   \item Determines the appropriate analysis cutoff time
#'   \item Adjusts time-to-event data for patients not yet recruited at cutoff
#'   \item Censors events occurring after the cutoff time
#'   \item Creates appropriate event indicators for statistical analysis
#' }
#'
#' The resulting dataset can be used directly with survival analysis functions
#' like \code{\link{lrtest}} and \code{\link{esthr}}.
#'
#' @examples
#' library(data.table)
#'
#' # Generate trial data for analysis
#' trial_data <- simTrial(
#'   nsim = 100,
#'   N = list(
#'     control = c(A = 25, B = 112, C = 113),
#'     treatment = c(A = 25, B = 112, C = 113)
#'   ),
#'   a.time = c(0, 5, 10, 15, 20, 25),
#'   intensity = c(3.5, 14.3, 28.9, 43.6, 45),
#'   e.time = list(
#'     control = list(A = c(0, Inf), B = c(0, Inf), C = c(0, Inf)),
#'     treatment = list(A = c(0, Inf), B = c(0, Inf), C = c(0, Inf))
#'   ),
#'   e.hazard = list(
#'     control = list(A = log(2) / 5.811, B = log(2) / 5.811, C = log(2) / 5.811),
#'     treatment = list(A = log(2) / 4.3, B = log(2) / 4.3, C = log(2) / 4.3)
#'   ),
#'   d.time = list(
#'     control = list(A = c(0, Inf), B = c(0, Inf), C = c(0, Inf)),
#'     treatment = list(A = c(0, Inf), B = c(0, Inf), C = c(0, Inf))
#'   ),
#'   d.hazard = list(
#'     control = list(A = 0.01, B = 0.01, C = 0.01),
#'     treatment = list(A = 0.01, B = 0.01, C = 0.01)
#'   ),
#'   seed = 1
#' )
#'
#' # Example 1: Event-driven analyses
#' # Interim at 142 events, interim at 248 events, final at 354 events
#' analysis_events <- analysisData(trial_data, E = c(142, 248, 354))
#'
#' # Check event counts by analysis
#' event_summary <- analysis_events[, .(
#'   total_events = sum(event),
#'   total_patients = .N,
#'   analysis_time = unique(analysis.time)
#' ), by = .(analysis, simID)]
#'
#' print(event_summary[simID == 1])  # Show first simulation
#'
#' # Perform log-rank tests at each analysis timepoint
#' lr_results <- analysis_events[simID == 1, {
#'   lr_stat <- lrtest(tte, event, group, 1, 2)
#'   p_value <- 1 - pchisq(lr_stat, 1)
#'   list(lr_statistic = lr_stat, p_value = p_value)
#' }, by = analysis]
#'
#' cat("Log-rank test results by analysis:\n")
#' print(lr_results)
#'
#' # Example 2: Time-driven analyses
#' # Analyses at 20, 25, and 30 months from study start
#' analysis_time <- analysisData(trial_data, followup = c(20, 25, 30))
#'
#' # Compare event counts between event-driven and time-driven
#' time_events <- analysis_time[, .(
#'   total_events = sum(event),
#'   total_patients = .N,
#'   analysis_time = unique(analysis.time)
#' ), by = .(analysis, simID)]
#'
#' print(time_events[simID == 1])
#'
#' # Example 3: Subgroup analysis capability
#' # Analyze treatment effect by subgroup at final analysis
#' final_analysis <- analysis_events[analysis == 3 & simID == 1]
#'
#' subgroup_results <- final_analysis[, {
#'   if (sum(event) >= 10) {  # Ensure sufficient events
#'     hr_result <- esthr(tte, event, group, 1, "LR")
#'     list(hazard_ratio = hr_result$HR, events = sum(event))
#'   } else {
#'     list(hazard_ratio = NA, events = sum(event))
#'   }
#' }, by = subgroup]
#'
#' cat("Subgroup analysis results:\n")
#' print(subgroup_results)
#'
#' # Example 4: Power analysis across simulations
#' # Calculate power for the final analysis (analysis 3)
#' power_results <- analysis_events[analysis == 3, {
#'   lr_stat <- lrtest(tte, event, group, 1, 2)
#'   p_value <- 1 - pchisq(lr_stat, 1)
#'   list(significant = p_value < 0.05, total_events = sum(event))
#' }, by = simID]
#'
#' power <- mean(power_results$significant)
#' cat("Statistical power at final analysis:", round(power, 3), "\n")
#'
#' # Distribution of event counts at final analysis
#' hist(power_results$total_events,
#'      main = "Distribution of Events at Final Analysis",
#'      xlab = "Number of Events", ylab = "Frequency", breaks = 20)
#'
#' # Example 5: Adaptive design simulation
#' # Early stopping for efficacy or futility
#' adaptive_results <- analysis_events[, {
#'   lr_stat <- lrtest(tte, event, group, 1, 2)
#'   p_value <- 1 - pchisq(lr_stat, 1)
#'
#'   # Simple stopping rules
#'   stop_efficacy <- (analysis <= 2 & p_value < 0.005) | (analysis == 3 & p_value < 0.05)
#'   stop_futility <- analysis <= 2 & p_value > 0.8
#'
#'   list(
#'     p_value = p_value,
#'     stop_efficacy = stop_efficacy,
#'     stop_futility = stop_futility,
#'     continue = !stop_efficacy & !stop_futility
#'   )
#' }, by = .(simID, analysis)]
#'
#' # Summary of adaptive design outcomes
#' adaptive_summary <- adaptive_results[, .(
#'   early_efficacy = any(stop_efficacy[analysis <= 2]),
#'   early_futility = any(stop_futility[analysis <= 2]),
#'   completed = all(!stop_efficacy[analysis <= 2]) & all(!stop_futility[analysis <= 2])
#' ), by = simID]
#'
#' cat("Adaptive design outcomes:\n")
#' cat("Early efficacy stop:", mean(adaptive_summary$early_efficacy), "\n")
#' cat("Early futility stop:", mean(adaptive_summary$early_futility), "\n")
#' cat("Completed to final:", mean(adaptive_summary$completed), "\n")
#'
#' @seealso
#' \code{\link{simTrial}} for generating the input trial data,
#' \code{\link{lrtest}} and \code{\link{esthr}} for statistical analysis,
#' \code{\link[survival]{Surv}} for creating survival objects
#'
#' @references
#' Jennison, C., & Turnbull, B. W. (1999). Group Sequential Methods with
#' Applications to Clinical Trials. Chapman and Hall/CRC.
#'
#' Proschan, M. A., Lan, K. K. G., & Wittes, J. T. (2006).
#' Statistical Monitoring of Clinical Trials: A Unified Approach. Springer.
#'
#' Wassmer, G., & Brannath, W. (2016). Group Sequential and Confirmatory
#' Adaptive Designs in Clinical Trials. Springer.
#'
#' @import data.table
#' @export
analysisData <- function(data, E = NULL, followup = NULL) {

  # Input validation
  if (is.null(E) && is.null(followup)) {
    stop("Either E or followup must be specified")
  }

  if (!is.null(E) && !is.null(followup)) {
    stop("Cannot specify both E and followup arguments")
  }

  # Ensure data is a data.table
  if (!is.data.table(data)) {
    data <- as.data.table(data)
  }

  # Sort data by simulation ID and total time for efficient processing
  setorder(data, simID, total)

  if (!is.null(E)) {
    # Event-driven analysis
    n_analyses <- length(E)
    n_rows <- nrow(data)

    # Create expanded dataset efficiently using data.table operations
    expanded_data <- data[rep(seq_len(n_rows), n_analyses)]

    # Add analysis indicator
    expanded_data[, analysis := rep(seq_len(n_analyses), each = n_rows)]

    # Calculate analysis times and event indicators by group
    # First, identify event times (where dropout != 1) for each simulation
    expanded_data[, `:=`(
      row_id = seq_len(.N),
      is_event = as.integer(dropout != 1)
    ), by = .(analysis, simID)]

    # Calculate cumulative event count and find analysis time
    expanded_data[, event_rank := cumsum(is_event), by = .(analysis, simID)]

    # Find the analysis time (total time of the E[analysis]-th event)
    analysis_times <- expanded_data[
      is_event == 1,
      .(analysis.time = total[E[analysis[1]]]),
      by = .(analysis, simID)
    ]

    # Merge analysis times back to the main dataset
    expanded_data <- expanded_data[analysis_times, on = .(analysis, simID)]

    # Calculate adjusted time-to-event and event indicator
    expanded_data[, `:=`(
      tte = ifelse(total > analysis.time,
                   analysis.time - accrual.time,
                   tte),
      event = as.integer(total <= analysis.time & dropout != 1)
    )]

    # Clean up temporary columns and filter
    expanded_data[, `:=`(row_id = NULL, is_event = NULL, event_rank = NULL)]
    expanded_data <- expanded_data[tte >= 0]

  } else {
    # Time-driven analysis
    n_analyses <- length(followup)
    n_rows <- nrow(data)

    # Create expanded dataset efficiently using data.table operations
    expanded_data <- data[rep(seq_len(n_rows), n_analyses)]

    # Add analysis indicator and analysis time
    expanded_data[, `:=`(
      analysis = rep(seq_len(n_analyses), each = n_rows),
      analysis.time = rep(rep(followup, each = n_rows))
    )]

    # Calculate adjusted time-to-event and event indicator
    expanded_data[, `:=`(
      tte = ifelse(total > analysis.time,
                   analysis.time - accrual.time,
                   tte),
      event = as.integer(total <= analysis.time & dropout != 1)
    )]

    # Filter out negative time-to-event
    expanded_data <- expanded_data[tte >= 0]
  }

  # Set optimal column order
  if ("subgroup" %in% names(expanded_data)) {
    column_order <- c("analysis", "simID", "group", "subgroup", "accrual.time",
                      "surv.time", "dropout.time", "tte", "total", "dropout",
                      "analysis.time", "event")
  } else {
    column_order <- c("analysis", "simID", "group", "accrual.time", "surv.time",
                      "dropout.time", "tte", "total", "dropout", "analysis.time", "event")
  }

  setcolorder(expanded_data, column_order)

  return(expanded_data)
}
